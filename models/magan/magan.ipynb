{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3c25caee",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'util'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_16944/188355649.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpsutil\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 29\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mutil\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mmodel_utils\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     30\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mutil\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msingle_loader\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mget_data_array\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mget_dataloader\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mutil\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mearly_stop\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mEarlyStopping\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mEarlyStoppingReachAccuracy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'util'"
     ]
    }
   ],
   "source": [
    "import yaml \n",
    "\n",
    "import os \n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import yaml\n",
    "import os \n",
    "import torch\n",
    "from  torch.utils.data import Dataset, DataLoader \n",
    "import sys\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import Parameter\n",
    "import math\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "import torch.nn as nn\n",
    "import time\n",
    "\n",
    "# module_path = \"C:\\\\Users\\\\Dung\\\\3D Objects\\\\Air-Quality-Prediction-Benchmark\"\n",
    "# if module_path not in sys.path:\n",
    "#     sys.path.append(module_path)\n",
    "\n",
    "import os, psutil\n",
    "from util import model as model_utils\n",
    "from util.single_loader import get_data_array, get_dataloader\n",
    "from util.early_stop import EarlyStopping, EarlyStoppingReachAccuracy\n",
    "from util.torch_util import weight_init\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import wandb\n",
    "import argparse\n",
    "import time\n",
    "from util.loss import r2_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9b324e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_array(config, target_station):\n",
    "    file_path = config['data_dir']\n",
    "\n",
    "    file_gauge = file_path + 'gauges/'\n",
    "\n",
    "    list_input_ft = config['input_features']\n",
    "    scaler = MinMaxScaler()\n",
    "    df = pd.read_csv(file_gauge  + f\"{target_station}.csv\")[list_input_ft]\n",
    "    arr = df.iloc[:,:].astype(np.float32).values\n",
    "\n",
    "    scaler.fit(arr)\n",
    "    transformed_data = scaler.transform(arr)\n",
    "    return transformed_data,  scaler\n",
    "\n",
    "def get_dataloader(data,  config, train_ratio = 0.3):\n",
    "    len_dataset = len(data)  \n",
    "    train_pct = config['train_size']\n",
    "    valid_pct = config['valid_size']\n",
    "    test_pct = config['test_size']\n",
    "\n",
    "    train_data = data[:int(len_dataset * train_pct * train_ratio)]\n",
    "    valid_data = data[int(len_dataset * (1 - test_pct - valid_pct)): int(len_dataset * (1 - test_pct))]\n",
    "    test_data = data[int(len_dataset * (1 - test_pct)):]\n",
    "    train_dataset = AQDataset(\n",
    "        data= train_data, \n",
    "        config=config\n",
    "    )\n",
    "    train_dataloader = DataLoader(\n",
    "        train_dataset, \n",
    "        batch_size=config['batch_size'],\n",
    "        shuffle=False, \n",
    "        drop_last=True\n",
    "    )\n",
    "    validation_dataset = AQDataset(\n",
    "        data=valid_data, \n",
    "        config=config\n",
    "    )\n",
    "    valid_dataloader = DataLoader(\n",
    "        validation_dataset,\n",
    "        batch_size=config['batch_size'],\n",
    "        shuffle=False, \n",
    "        drop_last=True\n",
    "    )\n",
    "\n",
    "    test_dataset = AQDataset(\n",
    "        data=test_data,\n",
    "        config=config\n",
    "    )\n",
    "    test_dataloader = DataLoader(\n",
    "        test_dataset,\n",
    "        batch_size=config['batch_size'],\n",
    "        shuffle=False, \n",
    "        drop_last=True\n",
    "    )\n",
    "\n",
    "#     if args.data_splitting == 'hold-out':\n",
    "#         train_dataset = AQDataset(\n",
    "#             data= train_data, \n",
    "#             config=config\n",
    "#         )\n",
    "#         train_dataloader = DataLoader(\n",
    "#             train_dataset, \n",
    "#             batch_size=config['batch_size'],\n",
    "#             shuffle=True, \n",
    "#             drop_last=True\n",
    "#         )\n",
    "#         validation_dataset = AQDataset(\n",
    "#             data=valid_data, \n",
    "#             config=config\n",
    "#         )\n",
    "#         valid_dataloader = DataLoader(\n",
    "#             validation_dataset,\n",
    "#             batch_size=config['batch_size'],\n",
    "#             shuffle=False, \n",
    "#             drop_last=True\n",
    "#         )\n",
    "\n",
    "#         test_dataset = AQDataset(\n",
    "#             data=test_data,\n",
    "#             config=config\n",
    "#         )\n",
    "#         test_dataloader = DataLoader(\n",
    "#             test_dataset,\n",
    "#             batch_size=config['batch_size'],\n",
    "#             shuffle=False, \n",
    "#             drop_last=True\n",
    "#         )\n",
    "    \n",
    "#     elif args.data_splitting == 'time-series-cross-validation':\n",
    "#         pass\n",
    "#     elif args.data_splitting == 'blocking-cross-validation':\n",
    "#         pass\n",
    "    return train_dataloader, valid_dataloader, test_dataloader\n",
    "\n",
    "class AQDataset(Dataset):\n",
    "    def __init__(self, data, config):\n",
    "        super().__init__()\n",
    "        self.data = data \n",
    "        self.config = config \n",
    "        self.input_len =  self.config['window_size']\n",
    "        self.output_len = self.config['output_size']\n",
    "\n",
    "        self.input_feats =  self.config[\"input_features\"]\n",
    "        self.target_feat = self.config['target_features']\n",
    "        self.target_ft_idx = self.config['input_features'].index(self.config['target_features'][0])\n",
    "    \n",
    "    def __getitem__(self, index: int):\n",
    "        x = self.data[\n",
    "            index: index + self.input_len, \n",
    "            :\n",
    "        ]\n",
    "        y = self.data[\n",
    "            index + self.input_len: index + self.input_len + self.output_len, \n",
    "            self.target_ft_idx\n",
    "        ]\n",
    "        return {\n",
    "            'x': torch.from_numpy(x),\n",
    "            'y': torch.from_numpy(y)\n",
    "        }\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return self.data.shape[0]  - self.input_len - self.output_len +1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e60eda12",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 24, 5])\n",
      "tensor([[0.2500, 0.2683, 0.2988,  ..., 0.3720, 0.3476, 0.3476],\n",
      "        [0.2683, 0.2988, 0.2378,  ..., 0.3476, 0.3476, 0.3323],\n",
      "        [0.2988, 0.2378, 0.2317,  ..., 0.3476, 0.3323, 0.3171],\n",
      "        ...,\n",
      "        [0.0366, 0.0488, 0.0305,  ..., 0.0793, 0.0976, 0.0762],\n",
      "        [0.0488, 0.0305, 0.0122,  ..., 0.0976, 0.0762, 0.0549],\n",
      "        [0.0305, 0.0122, 0.0610,  ..., 0.0762, 0.0549, 0.0793]])\n"
     ]
    }
   ],
   "source": [
    "config_path = '../../config/magan.yml'\n",
    "with open(config_path, 'r', encoding = \"utf-8\") as f:\n",
    "    config= yaml.safe_load(f)\n",
    "data, scaler = get_data_array(config,\"房山\") \n",
    "train_dataloader, valid_dataloader, test_dataloader = get_dataloader(data=data, config=config)\n",
    "\n",
    "for data in train_dataloader:\n",
    "    input = data['x']\n",
    "    print(input.shape)\n",
    "    y_fake = input[:,:,0]\n",
    "    print(y_fake)\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0506ca44",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "  def __init__(self,config,device): #,m,T,n\n",
    "    super(Encoder,self).__init__()\n",
    "    self.hidden_size = config['hidden_size']\n",
    "    self.batch_size = config['batch_size']\n",
    "    self.window_size = config['window_size']\n",
    "    self.driving_series = config['driving_series']\n",
    "    self.device = device\n",
    "    \n",
    "    #input attention\n",
    "    self.Ve = Parameter(torch.Tensor(self.window_size)).to(self.device)\n",
    "    self.We = Parameter(torch.Tensor(self.window_size,2*self.hidden_size)).to(self.device)\n",
    "    self.Ue = Parameter(torch.Tensor(self.window_size,self.window_size)).to(self.device)\n",
    "    self.LSTM1 = nn.LSTM(self.driving_series,self.hidden_size,1,batch_first = True).to(self.device)\n",
    "\n",
    "    #self attention\n",
    "    self.Wg = Parameter(torch.Tensor(self.hidden_size,self.batch_size)).to(self.device)\n",
    "    self.Wa = Parameter(torch.Tensor(self.batch_size,self.hidden_size)).to(self.device)\n",
    "    self.bg = Parameter(torch.Tensor(self.hidden_size,self.driving_series)).to(self.device)\n",
    "    self.ba = Parameter(torch.Tensor(self.batch_size,self.driving_series)).to(self.device)\n",
    "    self.LSTM2 = nn.LSTM(self.driving_series,self.hidden_size,1,batch_first = True).to(self.device)\n",
    "\n",
    "    #function\n",
    "    self.tanh = nn.Tanh()\n",
    "    self.sigmoid = nn.Sigmoid()\n",
    "    self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    self.reset_parameters()\n",
    "\n",
    "  def reset_parameters(self):\n",
    "    stdv = 1.0 / math.sqrt(self.hidden_size)\n",
    "    for weight in self.parameters():\n",
    "      weight.data.uniform_(-stdv, stdv)\n",
    "  \n",
    "  def forward(self,x,h,s):\n",
    "      batch, T,n = x.size()\n",
    "      h1 = (h,s)\n",
    "      h2 = (h,s)\n",
    "      input_attention = torch.zeros(batch,n,T).to(self.device)\n",
    "      self_attention = torch.zeros(batch,T,n).to(self.device)\n",
    "    # for i in range(batch):\n",
    "      for j in range(n):\n",
    "# #         print(\"H\",h.shape)\n",
    "# #         print('s', s.shape)\n",
    "#         print(\"Concat\", torch.cat((h,s),2).shape)\n",
    "#         print(self.We.shape)\n",
    "\n",
    "# #         print(self.We @ (torch.cat((h,s),2))\n",
    "        print(self.We @ torch.cat((h,s),2).permute((1,2,0)))\n",
    "#         print(self.We@ (torch.cat((h,s),2).transpose(2,1)))\n",
    "        e_k = self.Ve.T @ self.tanh(self.We@ (torch.cat((h,s),2).transpose(2,1) + self.Ue@x[:,:,j].T))\n",
    "#         print(e_k.shape)\n",
    "        a_k = self.softmax(e_k)\n",
    "        # print(a_k.shape)\n",
    "        input_attention[:,j,:] = a_k @ x[:,:,j]\n",
    "      for d in range(T):\n",
    "        g_t = self.tanh(self.Wg @ x[:,d,:] + self.bg)\n",
    "        a_t = self.sigmoid(self.Wa @ g_t + self.ba)\n",
    "        # print(a_t.shape)\n",
    "        # print(self_attention[:,d,:].shape)\n",
    "        self_attention[:,d,:] = a_t * x[:,d,:]\n",
    "      print(self_attention.sha, input_attention)\n",
    "      _,h1 = self.LSTM1(input_attention, h1)\n",
    "      _,h2 = self.LSTM2(self_attention.transpose(2,1),h2)\n",
    "      return torch.cat((h1[0],h2[0]),0), h1\n",
    "    \n",
    "  def init_hidden(self):\n",
    "    h = torch.zeros(1,self.batch_size,self.hidden_size).to(self.device)\n",
    "    c = torch.zeros(1,self.batch_size,self.hidden_size).to(self.device)\n",
    "    return h,c\n",
    "\n",
    "#generator\n",
    "class Generator(nn.Module):\n",
    "  def __init__(self,config,device): #p,T,n,m,k,w\n",
    "    super(Generator,self).__init__()\n",
    "    self.hidden_size = config['hidden_size']\n",
    "    self.num_filter = config['num_filter']\n",
    "    self.batch_size = config['batch_size']\n",
    "    self.window_size = config['window_size']\n",
    "    self.output_size = 1\n",
    "    self.hidden_size = config['hidden_size']\n",
    "    self.kernel_size = config['kernel_size']\n",
    "    self.device = device\n",
    "    #Parameter define\n",
    "    self.vd = Parameter(torch.Tensor(self.hidden_size)).to(self.device)\n",
    "    self.Wd = Parameter(torch.Tensor(self.hidden_size,2*self.hidden_size)).to(self.device)\n",
    "    self.Ud = Parameter(torch.Tensor(self.hidden_size,self.hidden_size)).to(self.device)\n",
    "#     self.w = Parameter(torch.Tensor(1,self.hidden_size + 1)).to(self.device)\n",
    "#     self.b = Parameter(torch.Tensor(self.output_size,1)).to(self.device)\n",
    "    self.linear = nn.Linear(self.hidden_size + 1,1).to(self.device)\n",
    "    #function\n",
    "    self.tanh = nn.Tanh()\n",
    "    self.softmax = nn.Softmax(dim=1)\n",
    "    self.relu = nn.LeakyReLU(0.2, inplace = True)\n",
    "\n",
    "    self.conv = nn.Conv1d(2,self.num_filter,self.kernel_size).to(self.device)\n",
    "    self.LSTM = nn.LSTM(self.output_size,self.hidden_size,1,batch_first = True).to(self.device)\n",
    "\n",
    "    self.reset_parameters()\n",
    "\n",
    "  def reset_parameters(self):\n",
    "    stdv = 1.0 / math.sqrt(self.hidden_size)\n",
    "    for weight in self.parameters():\n",
    "      weight.data.uniform_(-stdv, stdv)\n",
    "\n",
    "  def forward(self,Z,d,s,y_real):\n",
    "    # print(Z.shape)\n",
    "    H = self.relu(self.conv(Z.transpose(1,0)))\n",
    "#     print(\"H\", H)\n",
    "    ct = torch.zeros(self.batch_size,self.hidden_size).to(self.device)\n",
    "    for i in range(H.shape[1]):\n",
    "      l = self.vd.T @ self.tanh(self.Wd @ (torch.cat((d,s),2).transpose(2,1)) + self.Ud @ (H[:,i,:].T))\n",
    "#       print(\"l\",l)\n",
    "\n",
    "      B = self.softmax(l)\n",
    "      ct += B@H[:,i,:]\n",
    "      y_real = y_real\n",
    "#       print(\"Ct\", ct.shape)\n",
    "#       print(\"Y real\",y_real.shape)\n",
    "# #       y_fake = self.w @ torch.cat((y_real,ct),1) + self.b\n",
    "#       concat = torch.cat((y_real.unsqueeze(-1),ct),-1)\n",
    "      concat = torch.cat((y_real,ct),-1)\n",
    "      y_fake = self.linear(concat)\n",
    "#       print(y_fake)\n",
    "      _,(d,s) =  self.LSTM(y_fake.view(self.batch_size,1,self.output_size),(d,s))\n",
    "    return y_fake.view(self.batch_size,self.output_size),(d,s)\n",
    "\n",
    "  def init_hidden(self):\n",
    "    h = torch.zeros(1,self.batch_size,self.hidden_size).to(self.device)\n",
    "    c = torch.zeros(1,self.batch_size,self.hidden_size).to(self.device)\n",
    "    return h,c\n",
    "\n",
    "#discriminator\n",
    "class Discriminator(nn.Module):\n",
    "  def __init__(self,config, device):\n",
    "    super(Discriminator,self).__init__()\n",
    "    self.output_size = 1\n",
    "    self.batch_size = config['batch_size']\n",
    "    self.device = device\n",
    "    self.conv1 = nn.Conv1d(self.output_size,128,1).to(self.device)\n",
    "    self.conv2 = nn.Conv1d(128,256,1).to(self.device)\n",
    "    self.conv3 = nn.Conv1d(256,512,1).to(self.device)\n",
    "    self.linear = nn.Linear(512,self.output_size).to(self.device)\n",
    "    self.sigmoid = nn.Sigmoid()\n",
    "  def forward(self,x):\n",
    "    x = x.view(1,self.output_size,self.batch_size)\n",
    "    x = self.conv3(self.conv2(self.conv1(x)))\n",
    "    print(x)\n",
    "    x = self.linear(x.view(1,self.batch_size,512))\n",
    "    return self.sigmoid(x)\n",
    "\n",
    "class MARNN(nn.Module):\n",
    "  def __init__(self,config,device):\n",
    "    super(MARNN,self).__init__()\n",
    "    self.encode = Encoder(config,device)\n",
    "    self.decode = Generator(config,device)\n",
    "\n",
    "  def forward(self,x,y_real):\n",
    "    he,se = self.encode.init_hidden()\n",
    "    hd,sd = self.decode.init_hidden()\n",
    "    Z,_ = self.encode(x,he,se)\n",
    "    y_fake,h = self.decode(Z,hd,sd,y_real)\n",
    "    return y_fake\n",
    "\n",
    "class MAGAN(nn.Module):\n",
    "  def __init__(self,config,device):\n",
    "    super(MAGAN,self).__init__()\n",
    "    self.marnn = MARNN(config,device)\n",
    "    self.dis = Discriminator(config, device)\n",
    "\n",
    "  def forward(self,x,y_real):\n",
    "    out_f = self.marnn(x,y_real)\n",
    "    out = self.dis(out_f)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e9eb59b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeDistributedCNN(nn.Module):\n",
    "\n",
    "    def __init__(self, module, batch_first=False):\n",
    "        super(TimeDistributedCNN, self).__init__()\n",
    "        self.module = module\n",
    "        self.batch_first = batch_first\n",
    "\n",
    "    def forward(self, x):\n",
    "        ''' x size: (batch_size, time_steps, num_channels, input_size) '''\n",
    "        batch_size, time_steps, num_channels, input_size = x.size()\n",
    "        c_in = x.view(batch_size * time_steps, num_channels, input_size)\n",
    "        c_out = self.module(c_in)\n",
    "#         print(c_out.shape)\n",
    "        r_in = c_out.view(batch_size, time_steps, c_out.shape[1], c_out.shape[2])\n",
    "        if self.batch_first is False:\n",
    "            r_in = r_in.permute(1, 0, 2)\n",
    "\n",
    "        return r_in\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bba6c400",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdditiveAttention(nn.Module):\n",
    "  def __init__(self, key_size, query_size, num_hiddens, dropout):\n",
    "    super(AdditiveAttention, self).__init__(**kwargs)\n",
    "    self.W_k = nn.Linear(key_size, num_hiddens, bias=False)\n",
    "    self.W_q = nn.Linear(query_size, num_hiddens, bias=False)\n",
    "    self.w_v = nn.Linear(num_hiddens, 1, bias=False)\n",
    "    self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "  def forward(self, queries, keys, values):\n",
    "    queries, keys = self.W_q(queries), self.W_k(keys)\n",
    "    # After dimension expansion, shape of `queries`: (`batch_size`, no. of\n",
    "    # queries, 1, `num_hiddens`) and shape of `keys`: (`batch_size`, 1,\n",
    "    # no. of key-value pairs, `num_hiddens`). Sum them up with\n",
    "    # broadcasting\n",
    "    features = queries.unsqueeze(2) + keys.unsqueeze(1)\n",
    "    features = torch.tanh(features)\n",
    "    # There is only one output of `self.w_v`, so we remove the last\n",
    "    # one-dimensional entry from the shape. Shape of `scores`:\n",
    "    # (`batch_size`, no. of queries, no. of key-value pairs)\n",
    "    scores = self.w_v(features).squeeze(-1)\n",
    "    self.attention_weights = nn.functional.softmax(scores, dim=-1)\n",
    "    # Shape of `values`: (`batch_size`, no. of key-value pairs, value\n",
    "    # dimension)\n",
    "    return torch.bmm(self.dropout(self.attention_weights), values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "0567727f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "  def __init__(self,config,device): #,m,T,n\n",
    "    super(Encoder,self).__init__()\n",
    "    self.hidden_size = config['hidden_size']\n",
    "    self.window_size = config['window_size']\n",
    "    self.driving_series = config['driving_series']\n",
    "    self.device = device\n",
    "    \n",
    "    self.input_lstm = nn.LSTM(self.driving_series,self.hidden_size,1,batch_first = True).to(self.device)\n",
    "\n",
    "#     self.We = nn.Linear(self.hidden_size * 2, self.window_size, bias = False).to(self.device)\n",
    "#     self.Ue = nn.Linear(self.window_size, self.window_size, bias = False).to(self.device)\n",
    "#     self.Ve = nn.Linear(self.window_size, 1, bias = False).to(self.device)\n",
    "    self.We = nn.Linear(self.hidden_size * 2, self.hidden_size, bias = False).to(self.device)\n",
    "    self.Ue = nn.Linear(self.driving_series, self.hidden_size, bias = False).to(self.device)\n",
    "    self.Ve = nn.Linear(self.hidden_size, 1, bias = False).to(self.device)\n",
    "\n",
    "    self.LSTM1 = nn.LSTM(self.driving_series,self.hidden_size,1,batch_first = True).to(self.device)\n",
    "\n",
    "    #self attention\n",
    "#     self.Wg = nn.Linear(in_features = self.driving_series, out_features  = self.hidden_size).to(self.device)\n",
    "#     self.Wa = nn.Linear(in_features = self.hidden_size, out_features  = self.driving_series).to(self.device)\n",
    "    self.Wg = nn.Linear(in_features = self.driving_series, out_features  = self.hidden_size).to(self.device)\n",
    "    self.Wa = nn.Linear(in_features = self.hidden_size, out_features  = self.driving_series).to(self.device)\n",
    "\n",
    "    self.LSTM2 = nn.LSTM(self.driving_series,self.hidden_size,1,batch_first = True).to(self.device)\n",
    "\n",
    "    #function\n",
    "    self.tanh = nn.Tanh()\n",
    "    self.sigmoid = nn.Sigmoid()\n",
    "    self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    self.reset_parameters()\n",
    "\n",
    "  def reset_parameters(self):\n",
    "    stdv = 1.0 / math.sqrt(self.hidden_size)\n",
    "    for weight in self.parameters():\n",
    "      weight.data.uniform_(-stdv, stdv)\n",
    "  \n",
    "  def forward(self,x):\n",
    "      batch_size, T,n = x.size()\n",
    "      h, s = self.init_hidden(batch_size)\n",
    "      h1 = (h,s)\n",
    "      h2 = (h,s)\n",
    "      input_attention = torch.zeros(batch_size,T,n).to(self.device)\n",
    "      \n",
    "      # Calculate input attention\n",
    "#       output, (_,s) = self.input_lstm(x)\n",
    "      # Initialize the hidden state and cell state (1, batch_size, hidden_size)\n",
    "      (h,s) = (h,s)\n",
    "      for t in range(T):\n",
    "        #x_t: input at time step t (batch_size, input_features)\n",
    "        x_t = x[:,t,:].unsqueeze(1)\n",
    "        # Concatenate the hidden state and cell state [h,s] (batch_size, hidden_size * 2)\n",
    "        h_s = torch.cat((h.squeeze(0),s.squeeze(0)),-1)\n",
    "        h_s = h_s.unsqueeze(1).repeat(1, self.window_size, 1)\n",
    "        # Calculate the attention weights\n",
    "        e_t = self.Ve(self.tanh(self.We(h_s) + self.Ue(x)))\n",
    "        a_t = self.softmax(e_t.squeeze(-1)).unsqueeze(1)\n",
    "        # Calculate input attention\n",
    "        input_attention[:,t,:] = (a_t @ x).squeeze(1)\n",
    "        # Pass through an lstm layer to get the current hidden state and cell state\n",
    "        _,(h,s) = self.input_lstm(x_t, (h,s))\n",
    "        \n",
    "      # Calculate self attention\n",
    "      a = []\n",
    "      for d in range(T):\n",
    "        # input at time step t (batch_size, input_features)\n",
    "        xt = x[:,d,:]\n",
    "        g_t = self.tanh(self.Wg(xt))\n",
    "        a_t = self.sigmoid(self.Wa(g_t))\n",
    "        a.append(a_t)\n",
    "      a = torch.stack(a, dim = 2)\n",
    "      self_attention = a * x.transpose(2,1)\n",
    "        \n",
    "      # Pass input attention and self attention through 2 lstms\n",
    "      output_1,h1 = self.LSTM1(input_attention, h1)\n",
    "      output_2,h2 = self.LSTM2(self_attention.transpose(2,1),h2)\n",
    "      \n",
    "      # Concatenate 2 lstm outputs as latent space Z (batch_size, time_steps,hidden_size * 2)\n",
    "      z = torch.cat((output_1, output_2), dim = -1)\n",
    "      return z\n",
    "    \n",
    "  def init_hidden(self, batch_size):\n",
    "    h = torch.zeros(1,batch_size,self.hidden_size).to(self.device)\n",
    "    c = torch.zeros(1,batch_size,self.hidden_size).to(self.device)\n",
    "    return h,c\n",
    "\n",
    "#generator\n",
    "class Generator(nn.Module):\n",
    "  def __init__(self,config,device): #p,T,n,m,k,w\n",
    "    super(Generator,self).__init__()\n",
    "    self.hidden_size = config['hidden_size']\n",
    "    self.num_filter = config['num_filter']\n",
    "#     self.batch_size = config['batch_size']\n",
    "    self.window_size = config['window_size']\n",
    "    self.output_size = config['output_size']\n",
    "    self.hidden_size = config['hidden_size']\n",
    "    self.kernel_size = config['kernel_size']\n",
    "    self.device = device\n",
    "    #Parameter define\n",
    "#     self.Wd = nn.Linear(self.hidden_size * 2, self.hidden_size, bias = False).to(self.device)\n",
    "#     self.Ud = nn.Linear(self.hidden_size, self.hidden_size, bias = False).to(self.device)\n",
    "#     self.vd = nn.Linear(self.hidden_size, 1, bias = False).to(self.device)\n",
    "#     self.output_linear = nn.Linear((self.hidden_size) + 1, 1).to(self.device)\n",
    "    self.Wd = nn.Linear(self.hidden_size * 2 , self.hidden_size, bias = False).to(self.device)\n",
    "    self.Ud = nn.Linear(self.hidden_size, self.hidden_size, bias = False).to(self.device)\n",
    "    self.vd = nn.Linear(self.hidden_size, 1, bias = False).to(self.device)\n",
    "    self.output_linear = nn.Linear((self.hidden_size ) + 1, 1).to(self.device)\n",
    "\n",
    "    #function\n",
    "    self.tanh = nn.Tanh()\n",
    "    self.softmax = nn.Softmax(dim=-1)\n",
    "    self.relu = nn.ReLU()\n",
    "\n",
    "    self.conv = nn.Conv1d(1,self.num_filter,self.kernel_size, padding = 'same').to(self.device)\n",
    "    self.distributed_conv = TimeDistributedCNN(self.conv, batch_first = True)\n",
    "    self.LSTM = nn.LSTM(1,self.hidden_size,1,batch_first = True).to(self.device)\n",
    "    self.conv_linear = nn.Linear(self.num_filter * self.hidden_size * 2, self.hidden_size).to(self.device)\n",
    "\n",
    "    self.reset_parameters()\n",
    "\n",
    "  def reset_parameters(self):\n",
    "    stdv = 1.0 / math.sqrt(self.hidden_size)\n",
    "    for weight in self.parameters():\n",
    "      weight.data.uniform_(-stdv, stdv)\n",
    "\n",
    "  def forward(self,Z,y_real):\n",
    "    batch_size = Z.shape[0]\n",
    "    # Pass the latent space through time distributed conv\n",
    "    Z = Z.unsqueeze(2)\n",
    "    H = self.relu(self.distributed_conv(Z))\n",
    "    # H shape (batch_size,time_steps, num_filters, hidden_size * 2)\n",
    "    # Reshape H to (batch_size, time_steps, hidden_size)\n",
    "    \n",
    "    H = H.view(H.shape[0], H.shape[1], H.shape[2] * H.shape[3])\n",
    "    H = self.relu(self.conv_linear(H))\n",
    "    \n",
    "    # Attention and predict y\n",
    "    d, s = self.init_hidden(batch_size)\n",
    "    previous_y = y_real.unsqueeze(-1)\n",
    "    predictions = []\n",
    "    for t in range(self.output_size):\n",
    "        # Concat previous hidden state and cell state\n",
    "        d_s = torch.cat((d,s),2).squeeze(0)\n",
    "        d_s = d_s.unsqueeze(1).repeat(1, self.window_size, 1)\n",
    "        #Calculate attention\n",
    "        l_t = self.vd(self.tanh(self.Wd(d_s) + self.Ud(H)))\n",
    "        b_t = self.softmax(l_t.squeeze(-1))\n",
    "        b_t = b_t.unsqueeze(1)\n",
    "        # Calculate context vector\n",
    "        c_t = (b_t @ H).squeeze(1)\n",
    "        # Calculate prediction at time step t\n",
    "        y_t = self.output_linear(torch.cat((c_t, previous_y), dim = 1))\n",
    "        predictions.append(y_t)\n",
    "        y_t = y_t.unsqueeze(-1)\n",
    "        # Pass through an LSTM layer to get current hidden state, cell state\n",
    "        _,(d,s) = self.LSTM(y_t, (d,s))\n",
    "    predictions = torch.cat(predictions, dim = 1)\n",
    "    return predictions\n",
    "\n",
    "  def init_hidden(self, batch_size):\n",
    "    h = torch.zeros(1,batch_size,self.hidden_size).to(self.device)\n",
    "    c = torch.zeros(1,batch_size,self.hidden_size).to(self.device)\n",
    "    return h,c\n",
    "\n",
    "#discriminator\n",
    "class Discriminator(nn.Module):\n",
    "  def __init__(self,config, device):\n",
    "    super(Discriminator,self).__init__()\n",
    "    self.output_size = config['output_size']\n",
    "#     self.batch_size = config['batch_size']\n",
    "    self.device = device\n",
    "    self.kernel_size = config['kernel_size']\n",
    "    self.conv1 = nn.Sequential(nn.Conv1d(1,32,self.kernel_size, padding = 'same').to(self.device),nn.LeakyReLU())\n",
    "    self.conv2 = nn.Sequential(nn.Conv1d(32,64,self.kernel_size, padding = 'same').to(self.device),nn.LeakyReLU())\n",
    "    self.conv3 = nn.Sequential(nn.Conv1d(64,128,self.kernel_size, padding = 'same').to(self.device),nn.LeakyReLU())\n",
    "    self.linear = nn.Linear(128 * self.output_size,1).to(self.device)\n",
    "    self.sigmoid = nn.Sigmoid()\n",
    "  def forward(self,x):\n",
    "    batch_size = x.shape[0]\n",
    "    x = x.unsqueeze(1)\n",
    "    x = self.conv3(self.conv2(self.conv1(x)))\n",
    "    x = self.linear(x.view(batch_size,128 * self.output_size))\n",
    "    return self.sigmoid(x)\n",
    "\n",
    "class MARNN(nn.Module):\n",
    "  def __init__(self,config,device):\n",
    "    super(MARNN,self).__init__()\n",
    "    self.encode = Encoder(config,device)\n",
    "    self.decode = Generator(config,device)\n",
    "\n",
    "  def forward(self,x,y_real):\n",
    "#     he,se = self.encode.init_hidden()\n",
    "#     hd,sd = self.decode.init_hidden()\n",
    "    Z = self.encode(x)\n",
    "    y_fake = self.decode(Z,y_real)\n",
    "    return y_fake\n",
    "\n",
    "class MAGAN(nn.Module):\n",
    "  def __init__(self,config,device):\n",
    "    super(MAGAN,self).__init__()\n",
    "    self.marnn = MARNN(config,device)\n",
    "    self.encoder = self.marnn.encode\n",
    "    self.generator = self.marnn.decode\n",
    "    self.dis = Discriminator(config, device)\n",
    "\n",
    "  def forward(self,x,y_real):\n",
    "    out_f = self.marnn(x,y_real)\n",
    "    out = self.dis(out_f)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "8501dd3f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 1])\n",
      "tensor([[0.5039],\n",
      "        [0.5039],\n",
      "        [0.5039],\n",
      "        [0.5039],\n",
      "        [0.5039],\n",
      "        [0.5039],\n",
      "        [0.5039],\n",
      "        [0.5039],\n",
      "        [0.5039],\n",
      "        [0.5039],\n",
      "        [0.5039],\n",
      "        [0.5039],\n",
      "        [0.5039],\n",
      "        [0.5039],\n",
      "        [0.5039],\n",
      "        [0.5039],\n",
      "        [0.5039],\n",
      "        [0.5039],\n",
      "        [0.5039],\n",
      "        [0.5039],\n",
      "        [0.5039],\n",
      "        [0.5039],\n",
      "        [0.5039],\n",
      "        [0.5039],\n",
      "        [0.5039],\n",
      "        [0.5039],\n",
      "        [0.5039],\n",
      "        [0.5039],\n",
      "        [0.5039],\n",
      "        [0.5039],\n",
      "        [0.5039],\n",
      "        [0.5039],\n",
      "        [0.5039],\n",
      "        [0.5039],\n",
      "        [0.5039],\n",
      "        [0.5039],\n",
      "        [0.5039],\n",
      "        [0.5039],\n",
      "        [0.5039],\n",
      "        [0.5039],\n",
      "        [0.5039],\n",
      "        [0.5039],\n",
      "        [0.5039],\n",
      "        [0.5039],\n",
      "        [0.5039],\n",
      "        [0.5039],\n",
      "        [0.5039],\n",
      "        [0.5039],\n",
      "        [0.5039],\n",
      "        [0.5039],\n",
      "        [0.5039],\n",
      "        [0.5039],\n",
      "        [0.5039],\n",
      "        [0.5039],\n",
      "        [0.5039],\n",
      "        [0.5039],\n",
      "        [0.5039],\n",
      "        [0.5039],\n",
      "        [0.5039],\n",
      "        [0.5039],\n",
      "        [0.5039],\n",
      "        [0.5039],\n",
      "        [0.5039],\n",
      "        [0.5039],\n",
      "        [0.5039],\n",
      "        [0.5039],\n",
      "        [0.5039],\n",
      "        [0.5039],\n",
      "        [0.5039],\n",
      "        [0.5039],\n",
      "        [0.5039],\n",
      "        [0.5039],\n",
      "        [0.5039],\n",
      "        [0.5039],\n",
      "        [0.5039],\n",
      "        [0.5039],\n",
      "        [0.5039],\n",
      "        [0.5039],\n",
      "        [0.5039],\n",
      "        [0.5039],\n",
      "        [0.5039],\n",
      "        [0.5039],\n",
      "        [0.5039],\n",
      "        [0.5039],\n",
      "        [0.5039],\n",
      "        [0.5039],\n",
      "        [0.5039],\n",
      "        [0.5039],\n",
      "        [0.5039],\n",
      "        [0.5039],\n",
      "        [0.5039],\n",
      "        [0.5039],\n",
      "        [0.5039],\n",
      "        [0.5039],\n",
      "        [0.5039],\n",
      "        [0.5039],\n",
      "        [0.5039],\n",
      "        [0.5039],\n",
      "        [0.5039],\n",
      "        [0.5039],\n",
      "        [0.5039],\n",
      "        [0.5039],\n",
      "        [0.5039],\n",
      "        [0.5039],\n",
      "        [0.5039],\n",
      "        [0.5039],\n",
      "        [0.5039],\n",
      "        [0.5039],\n",
      "        [0.5039],\n",
      "        [0.5039],\n",
      "        [0.5039],\n",
      "        [0.5039],\n",
      "        [0.5039],\n",
      "        [0.5039],\n",
      "        [0.5039],\n",
      "        [0.5039],\n",
      "        [0.5039],\n",
      "        [0.5039],\n",
      "        [0.5039],\n",
      "        [0.5039],\n",
      "        [0.5039],\n",
      "        [0.5039],\n",
      "        [0.5039],\n",
      "        [0.5039],\n",
      "        [0.5039],\n",
      "        [0.5039],\n",
      "        [0.5039],\n",
      "        [0.5039]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5038],\n",
      "        [0.5038],\n",
      "        [0.5038],\n",
      "        [0.5038],\n",
      "        [0.5038],\n",
      "        [0.5038],\n",
      "        [0.5038],\n",
      "        [0.5038],\n",
      "        [0.5038],\n",
      "        [0.5038],\n",
      "        [0.5038],\n",
      "        [0.5038],\n",
      "        [0.5038],\n",
      "        [0.5038],\n",
      "        [0.5038],\n",
      "        [0.5038],\n",
      "        [0.5038],\n",
      "        [0.5038],\n",
      "        [0.5038],\n",
      "        [0.5038],\n",
      "        [0.5038],\n",
      "        [0.5038],\n",
      "        [0.5038],\n",
      "        [0.5038],\n",
      "        [0.5038],\n",
      "        [0.5038],\n",
      "        [0.5038],\n",
      "        [0.5038],\n",
      "        [0.5038],\n",
      "        [0.5038],\n",
      "        [0.5038],\n",
      "        [0.5038],\n",
      "        [0.5038],\n",
      "        [0.5038],\n",
      "        [0.5038],\n",
      "        [0.5038],\n",
      "        [0.5038],\n",
      "        [0.5038],\n",
      "        [0.5038],\n",
      "        [0.5038],\n",
      "        [0.5038],\n",
      "        [0.5038],\n",
      "        [0.5038],\n",
      "        [0.5038],\n",
      "        [0.5038],\n",
      "        [0.5038],\n",
      "        [0.5038],\n",
      "        [0.5038],\n",
      "        [0.5038],\n",
      "        [0.5038],\n",
      "        [0.5038],\n",
      "        [0.5038],\n",
      "        [0.5038],\n",
      "        [0.5038],\n",
      "        [0.5038],\n",
      "        [0.5038],\n",
      "        [0.5038],\n",
      "        [0.5038],\n",
      "        [0.5038],\n",
      "        [0.5038],\n",
      "        [0.5038],\n",
      "        [0.5038],\n",
      "        [0.5038],\n",
      "        [0.5038],\n",
      "        [0.5038],\n",
      "        [0.5038],\n",
      "        [0.5038],\n",
      "        [0.5038],\n",
      "        [0.5038],\n",
      "        [0.5038],\n",
      "        [0.5038],\n",
      "        [0.5038],\n",
      "        [0.5038],\n",
      "        [0.5038],\n",
      "        [0.5038],\n",
      "        [0.5038],\n",
      "        [0.5038],\n",
      "        [0.5038],\n",
      "        [0.5038],\n",
      "        [0.5038],\n",
      "        [0.5038],\n",
      "        [0.5038],\n",
      "        [0.5038],\n",
      "        [0.5038],\n",
      "        [0.5038],\n",
      "        [0.5038],\n",
      "        [0.5038],\n",
      "        [0.5038],\n",
      "        [0.5038],\n",
      "        [0.5038],\n",
      "        [0.5038],\n",
      "        [0.5040],\n",
      "        [0.5042],\n",
      "        [0.5042],\n",
      "        [0.5041],\n",
      "        [0.5039],\n",
      "        [0.5038],\n",
      "        [0.5038],\n",
      "        [0.5038],\n",
      "        [0.5038],\n",
      "        [0.5038],\n",
      "        [0.5038],\n",
      "        [0.5038],\n",
      "        [0.5038],\n",
      "        [0.5038],\n",
      "        [0.5038],\n",
      "        [0.5038],\n",
      "        [0.5038],\n",
      "        [0.5038],\n",
      "        [0.5038],\n",
      "        [0.5038],\n",
      "        [0.5038],\n",
      "        [0.5038],\n",
      "        [0.5038],\n",
      "        [0.5038],\n",
      "        [0.5038],\n",
      "        [0.5038],\n",
      "        [0.5038],\n",
      "        [0.5038],\n",
      "        [0.5038],\n",
      "        [0.5038],\n",
      "        [0.5039],\n",
      "        [0.5038],\n",
      "        [0.5039],\n",
      "        [0.5039],\n",
      "        [0.5038],\n",
      "        [0.5038],\n",
      "        [0.5038]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n"
     ]
    }
   ],
   "source": [
    "config_path = '../../config/magan_test.yml'\n",
    "with open(config_path, 'r', encoding = \"utf-8\") as f:\n",
    "    config= yaml.safe_load(f)\n",
    "data, scaler = get_data_array(config,\"房山\") \n",
    "train_dataloader, valid_dataloader, test_dataloader = get_dataloader(data=data, config=config)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "for data in train_dataloader:\n",
    "    input = data['x'].to(device)\n",
    "    target = data['y'].to(device)\n",
    "    previous_y = input[:,-1,0].to(device)\n",
    "    \n",
    "    model = MAGAN(config, device).to(device)\n",
    "    predictions = model.marnn(input, previous_y)\n",
    "    print(predictions.shape)\n",
    "    d_out_fake = model.dis(predictions)\n",
    "    d_out_real = model.dis(target)\n",
    "    print(d_out_fake)\n",
    "    print(d_out_real)\n",
    "\n",
    "    break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "a2b5068f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64.0"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1536 / 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "a1aa32af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.init as init\n",
    "def weight_init(m):\n",
    "    '''\n",
    "    Usage:\n",
    "        model = Model()\n",
    "        model.apply(weight_init)\n",
    "    '''\n",
    "    if isinstance(m, nn.Conv1d):\n",
    "        init.normal_(m.weight.data)\n",
    "        if m.bias is not None:\n",
    "            init.normal_(m.bias.data)\n",
    "    elif isinstance(m, nn.Conv2d):\n",
    "        init.xavier_normal_(m.weight.data)\n",
    "        if m.bias is not None:\n",
    "            init.normal_(m.bias.data)\n",
    "    elif isinstance(m, nn.Conv3d):\n",
    "        init.xavier_normal_(m.weight.data)\n",
    "        if m.bias is not None:\n",
    "            init.normal_(m.bias.data)\n",
    "    elif isinstance(m, nn.ConvTranspose1d):\n",
    "        init.normal_(m.weight.data)\n",
    "        if m.bias is not None:\n",
    "            init.normal_(m.bias.data)\n",
    "    elif isinstance(m, nn.ConvTranspose2d):\n",
    "        init.xavier_normal_(m.weight.data)\n",
    "        if m.bias is not None:\n",
    "            init.normal_(m.bias.data)\n",
    "    elif isinstance(m, nn.ConvTranspose3d):\n",
    "        init.xavier_normal_(m.weight.data)\n",
    "        if m.bias is not None:\n",
    "            init.normal_(m.bias.data)\n",
    "    elif isinstance(m, nn.BatchNorm1d):\n",
    "        init.normal_(m.weight.data, mean=1, std=0.02)\n",
    "        init.constant_(m.bias.data, 0)\n",
    "    elif isinstance(m, nn.BatchNorm2d):\n",
    "        init.normal_(m.weight.data, mean=1, std=0.02)\n",
    "        init.constant_(m.bias.data, 0)\n",
    "    elif isinstance(m, nn.BatchNorm3d):\n",
    "        init.normal_(m.weight.data, mean=1, std=0.02)\n",
    "        init.constant_(m.bias.data, 0)\n",
    "    elif isinstance(m, nn.Linear):\n",
    "        init.xavier_normal_(m.weight.data)\n",
    "        if m.bias is not None:\n",
    "            init.normal_(m.bias.data)\n",
    "    elif isinstance(m, nn.LSTM):\n",
    "        for param in m.parameters():\n",
    "            if len(param.shape) >= 2:\n",
    "                init.orthogonal_(param.data)\n",
    "            else:\n",
    "                init.normal_(param.data)\n",
    "    elif isinstance(m, nn.LSTMCell):\n",
    "        for param in m.parameters():\n",
    "            if len(param.shape) >= 2:\n",
    "                init.orthogonal_(param.data)\n",
    "            else:\n",
    "                init.normal_(param.data)\n",
    "    elif isinstance(m, nn.GRU):\n",
    "        for param in m.parameters():\n",
    "            if len(param.shape) >= 2:\n",
    "                init.orthogonal_(param.data)\n",
    "            else:\n",
    "                init.normal_(param.data)\n",
    "    elif isinstance(m, nn.GRUCell):\n",
    "        for param in m.parameters():\n",
    "            if len(param.shape) >= 2:\n",
    "                init.orthogonal_(param.data)\n",
    "            else:\n",
    "                init.normal_(param.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "9ec74127",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MAGANSupervisor():\n",
    "    def __init__(self, config, target_station, device):\n",
    "        self._epochs = config[\"epochs\"]\n",
    "        self._lr = config[\"lr\"]\n",
    "        self.window_size = config[\"window_size\"]\n",
    "\n",
    "        self._optimizer = config['optimizer']\n",
    "        self.optimizer = config['optimizer']\n",
    "\n",
    "        self.input_size = config['window_size']\n",
    "        self.input_dim = config['driving_series']\n",
    "\n",
    "        self._hidden_size = config['hidden_size']\n",
    "        self._output_size = config['output_size']\n",
    "\n",
    "        self._batch_size = config['batch_size']\n",
    "\n",
    "        # Data\n",
    "        self.target_station = target_station\n",
    "        transformed_data, scaler = get_data_array(config, target_station)\n",
    "        self._scaler = scaler \n",
    "        self.true_labels = torch.ones(self._batch_size,1).to(device)\n",
    "        self.fake_labels = torch.zeros(self._batch_size,1).to(device)\n",
    "        self.device = device\n",
    "        self._base_dir = os.path.join(config['base_dir'])\n",
    "        self._weights_path = os.path.join(self._base_dir, \"best.pth\")\n",
    "\n",
    "        train_dataloader, valid_dataloader, test_dataloader = get_dataloader(data=transformed_data, config=config)\n",
    "        self.train_dataloader = train_dataloader\n",
    "        self.valid_dataloader = valid_dataloader\n",
    "        self.test_dataloader = test_dataloader\n",
    "        first_it = next(iter(train_dataloader))   \n",
    "        X, y = first_it['x'], first_it['y']\n",
    "\n",
    "        self.config = config\n",
    "\n",
    "        # Model\n",
    "        self._model = MAGAN(config, device).to(self.device)\n",
    "        self._model.apply(weight_init)\n",
    "\n",
    "        \n",
    "        self._es = EarlyStopping(\n",
    "            patience=self.config['patience'],\n",
    "            verbose=True,\n",
    "            delta=0.0,\n",
    "            path=self._weights_path \n",
    "\n",
    "        )\n",
    "\n",
    "        self._es_until_reach_accuracy = EarlyStoppingReachAccuracy(\n",
    "            patience=self.config['patience'],\n",
    "            verbose=True,\n",
    "            delta=0.0,\n",
    "            path=self._weights_path   \n",
    "\n",
    "        )\n",
    "        self.train_ratio = 0.3\n",
    "        self.stop_until_reach_accuracy = False\n",
    "#         if args.experimental_mode == 'stop_until_reach_accuracy':\n",
    "#             self.stop_until_reach_accuracy = True\n",
    "\n",
    "    def train(self):\n",
    "        torch.autograd.set_detect_anomaly(True)\n",
    "        val_losses = []\n",
    "        clip = 5\n",
    "        model = self._model\n",
    "        criterion = torch.nn.MSELoss()\n",
    "        dis_criterion = torch.nn.BCELoss()\n",
    "        es = EarlyStopping(\n",
    "            patience=100,\n",
    "            verbose=True,\n",
    "            delta=0.0,\n",
    "            path=self._weights_path    \n",
    "        )\n",
    "        total_train_time = 0.0\n",
    "        if self.optimizer == 'adam':\n",
    "            optimizer_generator = torch.optim.Adam(model.generator.parameters(), lr=self._lr)\n",
    "            optimizer_dis = torch.optim.Adam(model.dis.parameters(), lr=self._lr)\n",
    "            optimizer_marnn_t = torch.optim.Adam(model.marnn.parameters(), lr=self._lr)\n",
    "        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer_marnn_t, mode='min',\n",
    "            factor=0.1, patience=3, threshold=0.0001, threshold_mode='abs')\n",
    "\n",
    "        # Train the model\n",
    "        for epoch in range(self._epochs):\n",
    "            if not es.early_stop:\n",
    "                epoch_trainD_loss = 0 \n",
    "                epoch_trainG_loss = 0\n",
    "                epoch_train_marnn_loss = 0\n",
    "                model.encoder.train()\n",
    "                model.generator.train()\n",
    "                model.marnn.train()\n",
    "                model.dis.train()\n",
    "                torch.cuda.synchronize()\n",
    "                train_it_start = int(round(time.time()*1000))\n",
    "                for data in tqdm(self.train_dataloader):\n",
    "                    \n",
    "                    input_data = data['x'].to(self.device)\n",
    "                    previous_y = input_data[:,-1,0].to(device)\n",
    "                    target = data['y'].to(self.device)\n",
    "                    \n",
    "                    model.encoder.zero_grad()\n",
    "                    model.generator.zero_grad()\n",
    "                    latent_space = model.encoder(input_data)\n",
    "                    y_fake = model.generator(latent_space, previous_y)\n",
    "                    #train discriminator\n",
    "                    model.dis.zero_grad()\n",
    "#                     y_fake = model.marnn(input_data,previous_y)\n",
    "#                     print(y_fake, target)\n",
    "                    d_out_fake = model.dis(y_fake)\n",
    "                    d_out_real = model.dis(target)\n",
    "#                     print(\"Fake discriminator\", d_out_fake)\n",
    "#                     print(\"Real discriminator\",d_out_real)\n",
    "                    # train discriminator with fake samples\n",
    "                    d_loss_fake = criterion(d_out_fake, self.fake_labels)\n",
    "                    d_loss_fake.backward()\n",
    "#                     optimizer_dis.step()\n",
    "\n",
    "                    # train discriminator with true samples\n",
    "                    d_loss_real = criterion(d_out_real, self.true_labels)\n",
    "                    d_loss_real.backward()\n",
    "#                     optimizer_dis.step()\n",
    "\n",
    "                    d_loss = d_loss_fake + d_loss_real\n",
    "                    epoch_trainD_loss  += d_loss.item()\n",
    "                    optimizer_dis.step()\n",
    "                    \n",
    "                    # Gradient clipping\n",
    "                    with torch.no_grad():\n",
    "                        for param in model.dis.parameters():\n",
    "                            param.clamp_(-0.01, 0.01)\n",
    "#                     for name, param in model.named_parameters():\n",
    "#                         print(name, param)\n",
    "\n",
    "                    #train generator\n",
    "                    model.generator.zero_grad()\n",
    "                    y_fake = model.generator(latent_space,previous_y)\n",
    "                    dis_out = model.dis(y_fake)\n",
    "                    g_loss = criterion(dis_out, self.true_labels)\n",
    "                    g_loss.backward()\n",
    "\n",
    "                    epoch_trainG_loss += g_loss.item()\n",
    "                    nn.utils.clip_grad_norm_(model.generator.parameters(), clip)\n",
    "\n",
    "                    optimizer_generator.step()\n",
    "\n",
    "                    #train marnn\n",
    "                    model.marnn.zero_grad()\n",
    "                    y_pred = model.marnn(input_data,previous_y)\n",
    "                    marnn_loss = criterion(y_pred,target)\n",
    "                    marnn_loss.backward()\n",
    "                    epoch_train_marnn_loss += marnn_loss.item()\n",
    "#                     print(\"G\", marnn_loss.item())\n",
    "                    nn.utils.clip_grad_norm_(model.marnn.parameters(), clip)\n",
    "                    optimizer_marnn_t.step()\n",
    "                \n",
    "                trainD_loss = epoch_trainD_loss / len(self.train_dataloader)\n",
    "                trainG_loss = epoch_trainG_loss / len(self.train_dataloader)\n",
    "                train_marnn_loss = epoch_train_marnn_loss / len(self.train_dataloader)\n",
    "                torch.cuda.synchronize()\n",
    "                time_elapsed = int(round(time.time()*1000)) - train_it_start\n",
    "                total_train_time += time_elapsed\n",
    "                \n",
    "                print('Train epoch {}: Discriminator train loss: {:.6f}\\tGenerator train loss: {:.6f}\\tTrain marnn Loss: {:.6f}'.format(epoch,trainD_loss,trainG_loss,train_marnn_loss))\n",
    "            #validation\n",
    "            model.eval()\n",
    "            epoch_val_loss = 0\n",
    "            with torch.no_grad():\n",
    "                for data in tqdm(self.valid_dataloader):\n",
    "                    batch_loss =  0\n",
    "                    input = data['x'].to(self.device)\n",
    "                    previous_y = input[:,-1,0].to(device)\n",
    "                    target = data['y'].to(self.device)\n",
    "#                     print(target.shape)\n",
    "                    outputs = model(input,previous_y)\n",
    "                    batch_loss = criterion(outputs,target)\n",
    "                    epoch_val_loss += batch_loss.item()\n",
    "                val_loss = epoch_val_loss / len(self.valid_dataloader)\n",
    "                val_losses.append(val_loss)\n",
    "                scheduler.step(val_loss)\n",
    "                print('Valid loss : {}'.format(val_loss))\n",
    "            \n",
    "            if self.stop_until_reach_accuracy:\n",
    "                es(train_r2_loss, model)\n",
    "            else:\n",
    "                es(val_loss, model)\n",
    "\n",
    "\n",
    "#         model_utils.save_checkpoint(model, optimizer_marnn, self._weights_path)\n",
    "        return val_losses[-1], total_train_time\n",
    "            \n",
    "    def test(self):\n",
    "        self._model.load_state_dict(torch.load(self._weights_path)[\"model_dict\"])\n",
    "        model = self._model\n",
    "        model.eval\n",
    "        groundtruth = []\n",
    "        predict = [] \n",
    "        lst_inference_time = []\n",
    "        with torch.no_grad():\n",
    "            i = 0\n",
    "            for data in tqdm(self.test_dataloader):\n",
    "                torch.cuda.synchronize()\n",
    "                inference_time_start = int(round(time.time()*1000))\n",
    "                if (i%self._output_size) == 0:\n",
    "                    x = data['x'].to(self.device)\n",
    "                    y = data['y'].to(self.device)\n",
    "                    target = data['target'].to(self.device)\n",
    "                    next = data['next'].to(self.device)\n",
    "                    for j in range(self._output_size):\n",
    "                        output = model.marnn(x,target)\n",
    "                        # import pdb; pdb.set_trace()\n",
    "                        pred_targets = target[:,1:self.window_size]\n",
    "                        target[:,0:self.window_size-1] = pred_targets\n",
    "                        target[:,self.window_size-1] = output[:,0]\n",
    "                        x_next = x[:,1:self.window_size,:]\n",
    "                        x[:,0:self.window_size - 1,:] = x_next\n",
    "                        x[:,self.window_size -1,:] = next[:,j,:]\n",
    "                        x[:,self.window_size -1,0] = output[:,0]\n",
    "\n",
    "\n",
    "                        groundtruth_final = y[:,j].view(self._batch_size,1).view(-1, 1).squeeze(-1)\n",
    "                        output_final = output.view(-1, 1).squeeze(-1)\n",
    "\n",
    "                        groundtruth += groundtruth_final.tolist()\n",
    "                        predict += output_final.tolist()\n",
    "                torch.cuda.synchronize()\n",
    "                total_inference_time = int(round(time.time()*1000)) - inference_time_start \n",
    "                lst_inference_time.append(total_inference_time)\n",
    "                i+=1\n",
    "                \n",
    "        predict_ = np.expand_dims(predict, 1)\n",
    "        groundtruth_ = np.expand_dims(groundtruth, 1)\n",
    "        predict_cpy_n_cols =  np.repeat(predict_, self.input_dim, axis=1)\n",
    "        groundtruth_cpy_n_cols = np.repeat(groundtruth_, self.input_dim, axis=1)\n",
    "        predicts = self._scaler.inverse_transform(predict_cpy_n_cols)[:, [0]]\n",
    "        groundtruths = self._scaler.inverse_transform(groundtruth_cpy_n_cols)[:,[0]]\n",
    "\n",
    "        \n",
    "        final_predicts = predicts.squeeze(-1)\n",
    "        final_groundtruths = groundtruths.squeeze(-1)\n",
    "        num_params = sum(p.numel() for p in model.parameters())\n",
    "        test_time = np.sum(np.array(lst_inference_time))\n",
    "\n",
    "        # model_utils.save_results(final_groundtruths, final_predicts, self._base_dir)\n",
    "        # model_utils.visualize(final_groundtruths, final_predicts, self._base_dir, \"results.png\")\n",
    "        # model_utils.save_results(final_groundtruths, final_predicts, self._base_dir, self.target_station, self._output_size)\n",
    "#         model_utils.save_results(final_groundtruths, final_predicts, self._base_dir, self.target_station, num_params, np.mean(np.array(lst_inference_time)))\n",
    "#         model_utils.visualize(final_groundtruths, final_predicts, self._base_dir, \"result_{}.png\".format(self.target_station) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "977e1fa8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.001"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config_path = '../../config/magan_test.yml'\n",
    "with open(config_path, 'r', encoding = \"utf-8\") as f:\n",
    "    config= yaml.safe_load(f)\n",
    "config['batch_size']\n",
    "config['lr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "3ee5d4e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                            | 0/9 [00:01<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Trying to backward through the graph a second time (or directly access saved tensors after they have already been freed). Saved intermediate values of the graph are freed when you call .backward() or autograd.grad(). Specify retain_graph=True if you need to backward through the graph a second time or if you need to access saved tensors after calling backward.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_14304/3822737056.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0msupervisor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMAGANSupervisor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_station\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"房山\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0msupervisor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_14304/555139306.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    137\u001b[0m                     \u001b[0mdis_out\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_fake\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    138\u001b[0m                     \u001b[0mg_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdis_out\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrue_labels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 139\u001b[1;33m                     \u001b[0mg_loss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    140\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    141\u001b[0m                     \u001b[0mepoch_trainG_loss\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mg_loss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\torch\\_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    305\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    306\u001b[0m                 inputs=inputs)\n\u001b[1;32m--> 307\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    308\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    309\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    152\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    153\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 154\u001b[1;33m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[0;32m    155\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    156\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Trying to backward through the graph a second time (or directly access saved tensors after they have already been freed). Saved intermediate values of the graph are freed when you call .backward() or autograd.grad(). Specify retain_graph=True if you need to backward through the graph a second time or if you need to access saved tensors after calling backward."
     ]
    }
   ],
   "source": [
    "config_path = '../../config/magan_test.yml'\n",
    "with open(config_path, 'r', encoding = \"utf-8\") as f:\n",
    "    config= yaml.safe_load(f)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "supervisor = MAGANSupervisor(config, target_station = \"房山\", device = device)\n",
    "supervisor.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "f07de739",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                           | 0/16 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'target'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_14304/269060030.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mutil\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetric\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmae\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrmse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmdape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0msupervisor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMAGANSupervisor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_station\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"房山\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0msupervisor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_14304/183776230.py\u001b[0m in \u001b[0;36mtest\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    193\u001b[0m                     \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'x'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    194\u001b[0m                     \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'y'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 195\u001b[1;33m                     \u001b[0mtarget\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'target'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    196\u001b[0m                     \u001b[0mnext\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'next'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    197\u001b[0m                     \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'target'"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from util.metric import mae, mse, rmse, mape, nse, mdape\n",
    "supervisor = MAGANSupervisor(config, target_station = \"房山\", device = device)\n",
    "supervisor.test()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e00bb67",
   "metadata": {},
   "source": [
    "### Train như regression bình thường"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "89e42b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MAGANSupervisor():\n",
    "    def __init__(self, config, target_station, device):\n",
    "        self._epochs = config[\"epochs\"]\n",
    "        self._lr = config[\"lr\"]\n",
    "        self.window_size = config[\"window_size\"]\n",
    "\n",
    "        self._optimizer = config['optimizer']\n",
    "        self.optimizer = config['optimizer']\n",
    "\n",
    "        self.input_size = config['window_size']\n",
    "        self.input_dim = config['driving_series']\n",
    "\n",
    "        self._hidden_size = config['hidden_size']\n",
    "        self._output_size = config['output_size']\n",
    "\n",
    "        self._batch_size = config['batch_size']\n",
    "\n",
    "        # Data\n",
    "        self.target_station = target_station\n",
    "        transformed_data, scaler = get_data_array(config, target_station)\n",
    "        self._scaler = scaler \n",
    "        self.true_labels = torch.ones(self._batch_size,1).to(device)\n",
    "        self.fake_labels = torch.zeros(self._batch_size,1).to(device)\n",
    "        self.device = device\n",
    "\n",
    "        train_dataloader, valid_dataloader, test_dataloader = get_dataloader(data=transformed_data, config=config)\n",
    "        self.train_dataloader = train_dataloader\n",
    "        self.valid_dataloader = valid_dataloader\n",
    "        self.test_dataloader = test_dataloader\n",
    "        first_it = next(iter(train_dataloader))   \n",
    "        X, y = first_it['x'], first_it['y']\n",
    "\n",
    "#         self._base_dir = model_utils.generate_log_dir(args)\n",
    "        self._base_dir = os.path.join(config['base_dir'])\n",
    "        self._weights_path = os.path.join(self._base_dir, \"best.pth\")\n",
    "\n",
    "        self.config = config\n",
    "\n",
    "        # Model\n",
    "        self._model = MARNN(config, device).to(self.device)\n",
    "        self._model.apply(weight_init)\n",
    "\n",
    "        \n",
    "        self._es = EarlyStopping(\n",
    "            patience=self.config['patience'],\n",
    "            verbose=True,\n",
    "            delta=0.0,\n",
    "            path = self._weights_path\n",
    "\n",
    "        )\n",
    "\n",
    "        self._es_until_reach_accuracy = EarlyStoppingReachAccuracy(\n",
    "            patience=self.config['patience'],\n",
    "            verbose=True,\n",
    "            delta=0.0,\n",
    "            path = self._weights_path \n",
    "\n",
    "        )\n",
    "        self.train_ratio = 0.3\n",
    "        self.stop_until_reach_accuracy = False\n",
    "#         if args.experimental_mode == 'stop_until_reach_accuracy':\n",
    "#             self.stop_until_reach_accuracy = True\n",
    "\n",
    "    def train(self):\n",
    "        torch.autograd.set_detect_anomaly(True)\n",
    "        val_losses = []\n",
    "        clip = 5\n",
    "        model = self._model\n",
    "        criterion = torch.nn.MSELoss()\n",
    "        es = EarlyStopping(\n",
    "            patience=100,\n",
    "            verbose=True,\n",
    "            delta=0.0,\n",
    "#             path=self._weights_path    \n",
    "            path = self._weights_path\n",
    "\n",
    "        )\n",
    "        total_train_time = 0.0\n",
    "        if self.optimizer == 'adam':\n",
    "            optimizer_marnn = torch.optim.Adam(model.parameters(), lr=self._lr)\n",
    "#             optimizer_dis = torch.optim.Adam(model.dis.parameters(), lr=self._lr)\n",
    "#             optimizer_marnn_t = torch.optim.Adam(model.marnn.parameters(), lr=self._lr)\n",
    "        # Train the model\n",
    "        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer_marnn, mode='min',\n",
    "            factor=0.1, patience=3, threshold=0.0001, threshold_mode='abs')\n",
    "\n",
    "        for epoch in range(self._epochs):\n",
    "            train_loss = []\n",
    "\n",
    "            if (not es.early_stop):\n",
    "#                 epoch_trainD_loss = 0 \n",
    "#                 epoch_trainG_loss = 0\n",
    "                model.train()\n",
    "#                 model.dis.train()\n",
    "                torch.cuda.synchronize()\n",
    "                train_it_start = int(round(time.time()*1000))\n",
    "                for data in tqdm(self.train_dataloader):\n",
    "                    input_data = data['x'].to(self.device)\n",
    "                    previous_y = input_data[:,-1,0].to(device)\n",
    "                    target = data['y'].to(self.device)\n",
    "\n",
    "                    model.zero_grad()\n",
    "                    y_pred = model(input_data,previous_y)\n",
    "                    marnn_loss = criterion(y_pred,target)\n",
    "                    train_loss.append(marnn_loss.item())\n",
    "                    marnn_loss.backward()\n",
    "#                     print(\"G\", marnn_loss.item())\n",
    "                    nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "                    optimizer_marnn.step()\n",
    "#                 train_loss = epoch_trainG_loss / len(self.train_dataloader)\n",
    "                torch.cuda.synchronize()\n",
    "                time_elapsed = int(round(time.time()*1000)) - train_it_start\n",
    "                total_train_time += time_elapsed\n",
    "                \n",
    "#                 print('Train epoch {}: Discriminator train loss: {:.6f}\\tMARNN train loss: {:.6f}\\tTrain marnn Loss: {:.6f}'.format(epoch,epoch_trainD_loss,epoch_trainG_loss,marnn_loss.item()))\n",
    "                print('Train epoch {}: \\tMARNN train loss: {:.6f}'.format(epoch,sum(train_loss)/len(train_loss)))\n",
    "\n",
    "            #validation\n",
    "            model.eval()\n",
    "            epoch_val_loss = 0\n",
    "            with torch.no_grad():\n",
    "                for data in tqdm(self.valid_dataloader):\n",
    "                    batch_loss =  0\n",
    "                    input = data['x'].to(self.device)\n",
    "                    previous_y = input[:,-1,0].to(device)\n",
    "                    target = data['y'].to(self.device)\n",
    "#                     print(target.shape)\n",
    "                    outputs = model(input,previous_y)\n",
    "                    batch_loss = criterion(outputs,target)\n",
    "                    epoch_val_loss += batch_loss.item()\n",
    "                val_loss = epoch_val_loss / len(self.valid_dataloader)\n",
    "                val_losses.append(val_loss)\n",
    "                scheduler.step(val_loss)\n",
    "                print('Valid loss : {}'.format(val_loss))\n",
    "            \n",
    "            if self.stop_until_reach_accuracy:\n",
    "                es(train_r2_loss, model)\n",
    "            else:\n",
    "                es(val_loss, model)\n",
    "\n",
    "\n",
    "#         model_utils.save_checkpoint(model, optimizer_marnn, self._weights_path)\n",
    "        return val_losses[-1], total_train_time\n",
    "            \n",
    "    def test(self):\n",
    "        criterion = nn.MSELoss()\n",
    "        self._model.load_state_dict(torch.load(self._weights_path)[\"model_dict\"])\n",
    "        model = self._model\n",
    "        groundtruth = []\n",
    "        predict = [] \n",
    "        lst_inference_time = []\n",
    "        model.eval()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for data in tqdm(self.test_dataloader):\n",
    "                x = data['x'].to(self.device)\n",
    "                previous_y = x[:,-1,0].to(device)\n",
    "\n",
    "                y = data['y'].to(self.device)\n",
    "\n",
    "                torch.cuda.synchronize()\n",
    "                inference_time_start = int(round(time.time()*1000))\n",
    "\n",
    "                output = model(x,previous_y)\n",
    "\n",
    "                torch.cuda.synchronize()\n",
    "                total_inference_time = int(round(time.time()*1000)) - inference_time_start \n",
    "                lst_inference_time.append(total_inference_time)\n",
    "\n",
    "                groundtruth_final = y.view(-1, 1).squeeze(-1)\n",
    "                output_final = output.view(-1, 1).squeeze(-1)\n",
    "\n",
    "                groundtruth += groundtruth_final.tolist()\n",
    "                predict += output_final.tolist()\n",
    "\n",
    "        predict_ = np.expand_dims(predict, 1)\n",
    "        groundtruth_ = np.expand_dims(groundtruth, 1)\n",
    "        predict_cpy_n_cols =  np.repeat(predict_, self.input_dim, axis=1)\n",
    "        groundtruth_cpy_n_cols = np.repeat(groundtruth_, self.input_dim, axis=1)\n",
    "\n",
    "        predicts = self._scaler.inverse_transform(predict_cpy_n_cols)[:, [0]]\n",
    "        groundtruths = self._scaler.inverse_transform(groundtruth_cpy_n_cols)[:,[0]]\n",
    "\n",
    "        final_predicts = predicts.squeeze(-1)\n",
    "        final_groundtruths = groundtruths.squeeze(-1)\n",
    "        m_mae = mae( final_groundtruths , final_predicts)\n",
    "        m_mape = mape( final_groundtruths , final_predicts)\n",
    "        m_rmse = rmse( final_groundtruths , final_predicts)\n",
    "        m_mse = mse( final_groundtruths , final_predicts)\n",
    "        m_r2score = r2_score( final_groundtruths , final_predicts)\n",
    "        m_mdape = mdape( final_groundtruths , final_predicts)\n",
    "        print(\"MAE: \", m_mae)\n",
    "        print(\"MAPE: \", m_mape)\n",
    "        print(\"RMSE: \", m_rmse)\n",
    "        print(\"MSE: \", m_mse)\n",
    "        print(\"R2: \", m_r2score)\n",
    "        print(\"MDAE: \", m_mdape)\n",
    "\n",
    "\n",
    "#         model_utils.save_results(final_groundtruths, final_predicts, self._base_dir)\n",
    "#         model_utils.visualize(final_groundtruths, final_predicts, self._base_dir, \"results.png\")\n",
    "\n",
    "#         with torch.no_grad():\n",
    "#             i = 0\n",
    "\n",
    "#             for data in tqdm(self.test_dataloader):\n",
    "#                 torch.cuda.synchronize()\n",
    "#                 inference_time_start = int(round(time.time()*1000))\n",
    "#                 if (i%self._output_size) == 0:\n",
    "#                     input_data = data['x'].to(self.device)\n",
    "#                     previous_y = input_data[:,-1,0].to(device)\n",
    "#                     target = data['y'].to(self.device)\n",
    "#                     output = modet(input_data, previous_y)\n",
    "#                     print(output)\n",
    "#                     next = data['next'].to(self.device)\n",
    "#                     for j in range(self._output_size):\n",
    "                        \n",
    "#                         output = model(x,target)\n",
    "#                         # import pdb; pdb.set_trace()\n",
    "#                         pred_targets = target[:,1:self.window_size]\n",
    "#                         target[:,0:self.window_size-1] = pred_targets\n",
    "#                         target[:,self.window_size-1] = output[:,0]\n",
    "#                         x_next = x[:,1:self.window_size,:]\n",
    "#                         x[:,0:self.window_size - 1,:] = x_next\n",
    "#                         x[:,self.window_size -1,:] = next[:,j,:]\n",
    "#                         x[:,self.window_size -1,0] = output[:,0]\n",
    "\n",
    "\n",
    "#                         groundtruth_final = y[:,j].view(self._batch_size,1).view(-1, 1).squeeze(-1)\n",
    "#                         output_final = output.view(-1, 1).squeeze(-1)\n",
    "\n",
    "#                         groundtruth += groundtruth_final.tolist()\n",
    "#                         predict += output_final.tolist()\n",
    "#                 torch.cuda.synchronize()\n",
    "#                 total_inference_time = int(round(time.time()*1000)) - inference_time_start \n",
    "#                 lst_inference_time.append(total_inference_time)\n",
    "#                 i+=1\n",
    "                \n",
    "#         predict_ = np.expand_dims(predict, 1)\n",
    "#         groundtruth_ = np.expand_dims(groundtruth, 1)\n",
    "#         predict_cpy_n_cols =  np.repeat(predict_, self.input_dim, axis=1)\n",
    "#         groundtruth_cpy_n_cols = np.repeat(groundtruth_, self.input_dim, axis=1)\n",
    "#         predicts = self._scaler.inverse_transform(predict_cpy_n_cols)[:, [0]]\n",
    "#         groundtruths = self._scaler.inverse_transform(groundtruth_cpy_n_cols)[:,[0]]\n",
    "\n",
    "        \n",
    "#         final_predicts = predicts.squeeze(-1)\n",
    "#         final_groundtruths = groundtruths.squeeze(-1)\n",
    "#         num_params = sum(p.numel() for p in model.parameters())\n",
    "#         test_time = np.sum(np.array(lst_inference_time))\n",
    "\n",
    "#         model_utils.save_results(final_groundtruths, final_predicts, self._base_dir)\n",
    "#         model_utils.visualize(final_groundtruths, final_predicts, self._base_dir, \"results.png\")\n",
    "        # model_utils.save_results(final_groundtruths, final_predicts, self._base_dir, self.target_station, self._output_size)\n",
    "#         model_utils.save_results(final_groundtruths, final_predicts, self._base_dir, self.target_station, num_params, np.mean(np.array(lst_inference_time)))\n",
    "#         model_utils.visualize(final_groundtruths, final_predicts, self._base_dir, \"result_{}.png\".format(self.target_station) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "12a92dba",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 19/19 [00:30<00:00,  1.63s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train epoch 0: \tMARNN train loss: 945.031763\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 33/33 [00:00<00:00, 41.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid loss : 0.1947392662140456\n",
      "Validation loss decreased (inf --> 0.194739).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 19/19 [00:18<00:00,  1.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train epoch 1: \tMARNN train loss: 0.075034\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 33/33 [00:00<00:00, 40.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid loss : 0.044985867980303185\n",
      "Validation loss decreased (0.194739 --> 0.044986).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 19/19 [00:19<00:00,  1.05s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train epoch 2: \tMARNN train loss: 0.052580\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 33/33 [00:00<00:00, 37.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid loss : 0.02279600640758872\n",
      "Validation loss decreased (0.044986 --> 0.022796).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 19/19 [00:18<00:00,  1.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train epoch 3: \tMARNN train loss: 0.034100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 33/33 [00:00<00:00, 44.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid loss : 0.013084884246133945\n",
      "Validation loss decreased (0.022796 --> 0.013085).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 19/19 [00:20<00:00,  1.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train epoch 4: \tMARNN train loss: 0.025042\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 33/33 [00:01<00:00, 32.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid loss : 0.010265517711752293\n",
      "Validation loss decreased (0.013085 --> 0.010266).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 19/19 [00:19<00:00,  1.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train epoch 5: \tMARNN train loss: 0.019313\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 33/33 [00:00<00:00, 42.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid loss : 0.008202253163538197\n",
      "Validation loss decreased (0.010266 --> 0.008202).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 19/19 [00:19<00:00,  1.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train epoch 6: \tMARNN train loss: 0.015500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 33/33 [00:00<00:00, 43.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid loss : 0.006516639065618317\n",
      "Validation loss decreased (0.008202 --> 0.006517).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 19/19 [00:21<00:00,  1.13s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train epoch 7: \tMARNN train loss: 0.012931\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 33/33 [00:00<00:00, 39.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid loss : 0.005463528122301354\n",
      "Validation loss decreased (0.006517 --> 0.005464).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 19/19 [00:54<00:00,  2.86s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train epoch 8: \tMARNN train loss: 0.011265\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 33/33 [00:01<00:00, 26.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid loss : 0.004810992353172464\n",
      "Validation loss decreased (0.005464 --> 0.004811).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 19/19 [00:23<00:00,  1.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train epoch 9: \tMARNN train loss: 0.010212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 33/33 [00:00<00:00, 42.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid loss : 0.0043970540864393115\n",
      "Validation loss decreased (0.004811 --> 0.004397).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 19/19 [00:19<00:00,  1.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train epoch 10: \tMARNN train loss: 0.009564\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 33/33 [00:00<00:00, 44.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid loss : 0.004147045931665961\n",
      "Validation loss decreased (0.004397 --> 0.004147).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 19/19 [00:27<00:00,  1.47s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train epoch 11: \tMARNN train loss: 0.009178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 33/33 [00:00<00:00, 34.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid loss : 0.004002024571298424\n",
      "Validation loss decreased (0.004147 --> 0.004002).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 19/19 [00:28<00:00,  1.50s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train epoch 12: \tMARNN train loss: 0.008956\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 33/33 [00:01<00:00, 26.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid loss : 0.00391999709730347\n",
      "Validation loss decreased (0.004002 --> 0.003920).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 19/19 [00:27<00:00,  1.44s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train epoch 13: \tMARNN train loss: 0.008832\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 33/33 [00:00<00:00, 37.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid loss : 0.003875120103740218\n",
      "Validation loss decreased (0.003920 --> 0.003875).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 19/19 [00:24<00:00,  1.29s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train epoch 14: \tMARNN train loss: 0.008765\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 33/33 [00:00<00:00, 34.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid loss : 0.003851331724559493\n",
      "Validation loss decreased (0.003875 --> 0.003851).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 19/19 [00:23<00:00,  1.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train epoch 15: \tMARNN train loss: 0.008729\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 33/33 [00:00<00:00, 37.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid loss : 0.0038390339856656888\n",
      "Validation loss decreased (0.003851 --> 0.003839).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 19/19 [00:32<00:00,  1.70s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train epoch 16: \tMARNN train loss: 0.008711\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 33/33 [00:00<00:00, 33.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid loss : 0.003832809246060523\n",
      "Validation loss decreased (0.003839 --> 0.003833).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 19/19 [00:31<00:00,  1.68s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train epoch 17: \tMARNN train loss: 0.008702\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 33/33 [00:00<00:00, 36.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid loss : 0.0038296947499144485\n",
      "Validation loss decreased (0.003833 --> 0.003830).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 19/19 [00:24<00:00,  1.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train epoch 18: \tMARNN train loss: 0.008685\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 33/33 [00:00<00:00, 34.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid loss : 0.0038300186773113005\n",
      "EarlyStopping counter: 1 out of 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 19/19 [00:23<00:00,  1.26s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train epoch 19: \tMARNN train loss: 0.008685\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 33/33 [00:00<00:00, 36.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid loss : 0.003830655160444704\n",
      "EarlyStopping counter: 2 out of 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|████▎                                                                              | 1/19 [00:01<00:33,  1.88s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_14304/3822737056.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0msupervisor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMAGANSupervisor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_station\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"房山\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0msupervisor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_14304/1570465008.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    101\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    102\u001b[0m                     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 103\u001b[1;33m                     \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_data\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mprevious_y\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    104\u001b[0m                     \u001b[0mmarnn_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    105\u001b[0m                     \u001b[0mtrain_loss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmarnn_loss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_14304/959374269.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x, y_real)\u001b[0m\n\u001b[0;32m    194\u001b[0m \u001b[1;31m#     he,se = self.encode.init_hidden()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    195\u001b[0m \u001b[1;31m#     hd,sd = self.decode.init_hidden()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 196\u001b[1;33m     \u001b[0mZ\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    197\u001b[0m     \u001b[0my_fake\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mZ\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_real\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0my_fake\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_14304/959374269.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     56\u001b[0m         \u001b[0mh_s\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mh_s\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwindow_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m         \u001b[1;31m# Calculate the attention weights\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 58\u001b[1;33m         \u001b[0me_t\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mVe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtanh\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mWe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mh_s\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mUe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     59\u001b[0m         \u001b[0ma_t\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me_t\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m         \u001b[1;31m# Calculate input attention\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\torch\\nn\\modules\\linear.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    101\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    102\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 103\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    104\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    105\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mlinear\u001b[1;34m(input, weight, bias)\u001b[0m\n\u001b[0;32m   1846\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhas_torch_function_variadic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1847\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlinear\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1848\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1849\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1850\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python38\\lib\\traceback.py\u001b[0m in \u001b[0;36mformat_stack\u001b[1;34m(f, limit)\u001b[0m\n\u001b[0;32m    195\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mf\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    196\u001b[0m         \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getframe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf_back\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 197\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mformat_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mextract_stack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlimit\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlimit\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    198\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    199\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python38\\lib\\traceback.py\u001b[0m in \u001b[0;36mextract_stack\u001b[1;34m(f, limit)\u001b[0m\n\u001b[0;32m    209\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mf\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m         \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getframe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf_back\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 211\u001b[1;33m     \u001b[0mstack\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mStackSummary\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextract\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwalk_stack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlimit\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlimit\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    212\u001b[0m     \u001b[0mstack\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreverse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    213\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mstack\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python38\\lib\\traceback.py\u001b[0m in \u001b[0;36mextract\u001b[1;34m(klass, frame_gen, limit, lookup_lines, capture_locals)\u001b[0m\n\u001b[0;32m    360\u001b[0m                 filename, lineno, name, lookup_line=False, locals=f_locals))\n\u001b[0;32m    361\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mfilename\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfnames\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 362\u001b[1;33m             \u001b[0mlinecache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheckcache\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    363\u001b[0m         \u001b[1;31m# If immediate lookup was desired, trigger lookups now.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    364\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlookup_lines\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\IPython\\core\\compilerop.py\u001b[0m in \u001b[0;36mcheck_linecache_ipython\u001b[1;34m(*args)\u001b[0m\n\u001b[0;32m    183\u001b[0m     \"\"\"\n\u001b[0;32m    184\u001b[0m     \u001b[1;31m# First call the original checkcache as intended\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 185\u001b[1;33m     \u001b[0mlinecache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_checkcache_ori\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    186\u001b[0m     \u001b[1;31m# Then, update back the cache with our data, so that tracebacks related\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    187\u001b[0m     \u001b[1;31m# to our compiled codes can be produced.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python38\\lib\\linecache.py\u001b[0m in \u001b[0;36mcheckcache\u001b[1;34m(filename)\u001b[0m\n\u001b[0;32m     72\u001b[0m             \u001b[1;32mcontinue\u001b[0m   \u001b[1;31m# no-op for files loaded via a __loader__\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 74\u001b[1;33m             \u001b[0mstat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfullname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     75\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m             \u001b[1;32mdel\u001b[0m \u001b[0mcache\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "config_path = '../../config/magan_test.yml'\n",
    "with open(config_path, 'r', encoding = \"utf-8\") as f:\n",
    "    config= yaml.safe_load(f)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "supervisor = MAGANSupervisor(config, target_station = \"房山\", device = device)\n",
    "supervisor.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "29e8eb07",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 33/33 [00:00<00:00, 36.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE:  6.821328729159084\n",
      "MAPE:  36.27126804665093\n",
      "RMSE:  10.264101944082617\n",
      "MSE:  105.35178871852055\n",
      "R2:  0.9590084283700707\n",
      "MDAE:  11.598088172249845\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from util.metric import mae, mse, rmse, mape, nse, mdape\n",
    "supervisor = MAGANSupervisor(config, target_station = \"房山\", device = device)\n",
    "supervisor.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "70d543a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config['output_size']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52db77b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sửa conv"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
